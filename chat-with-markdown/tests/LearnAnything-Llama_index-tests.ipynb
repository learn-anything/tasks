{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Note: Responses from local models can be quite slow, especially with 8-bit quantization.\n",
        "\n",
        "With 4bit quantization, llama2-7b-chat uses about 8GB of VRAM"
      ],
      "metadata": {
        "id": "wSl7lrrtMTHw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WX6WvijnMNWq"
      },
      "outputs": [],
      "source": [
        "!pip install llama-index transformers accelerate bitsandbytes"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## test wiki\n",
        "%%sh\n",
        "git clone https://github.com/learn-anything/seed.git"
      ],
      "metadata": {
        "id": "rWHbguToMcLo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ObsidianReader, VectorStoreIndex\n",
        "documents = ObsidianReader(\n",
        "    \"seed/wiki/nikita\"\n",
        ").load_data()"
      ],
      "metadata": {
        "id": "iXW-ADV0Mgph"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# huggingface api token for downloading llama2\n",
        "hf_token = \"hf_...\""
      ],
      "metadata": {
        "id": "tvfJszsrMjQz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from transformers import BitsAndBytesConfig\n",
        "from llama_index.prompts import PromptTemplate\n",
        "from llama_index.llms import HuggingFaceLLM\n",
        "\n",
        "quantization_config = BitsAndBytesConfig(\n",
        "    load_in_4bit=True,\n",
        "    bnb_4bit_compute_dtype=torch.float16,\n",
        "    bnb_4bit_quant_type=\"nf4\",\n",
        "    bnb_4bit_use_double_quant=True,\n",
        ")\n",
        "\n",
        "llm = HuggingFaceLLM(\n",
        "    model_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    tokenizer_name=\"meta-llama/Llama-2-7b-chat-hf\",\n",
        "    query_wrapper_prompt=PromptTemplate(\"\"\"<s> [INST] <<SYS>>\n",
        "        You extract information from the given context and answer questions about it only, if the question is not answered in the context asnwer \"NA\". The author is named nikita. Answer shortly and omit urls.\n",
        "        <</SYS>> {query_str} [/INST] \"\"\"),\n",
        "    context_window=3900,\n",
        "    model_kwargs={\"token\": hf_token, \"quantization_config\": quantization_config},\n",
        "    tokenizer_kwargs={\"token\": hf_token},\n",
        "    device_map=\"auto\",\n",
        ")"
      ],
      "metadata": {
        "id": "t6W3iYDiMnFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import ServiceContext\n",
        "\n",
        "service_context = ServiceContext.from_defaults(llm=llm, embed_model=\"local:BAAI/bge-small-en-v1.5\")"
      ],
      "metadata": {
        "id": "BzKUgGIFMrC_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Index Setup"
      ],
      "metadata": {
        "id": "_iYeofUlS6_D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "vector_index = VectorStoreIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "Jz173lnJS8cZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index import SummaryIndex\n",
        "\n",
        "summary_index = SummaryIndex.from_documents(documents, service_context=service_context)"
      ],
      "metadata": {
        "id": "CuGwYVl5S-GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpful Imports / Logging"
      ],
      "metadata": {
        "id": "pxFrAm_bTCYY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from llama_index.response.notebook_utils import display_response"
      ],
      "metadata": {
        "id": "ghqk6C04TD3b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ],
      "metadata": {
        "id": "6YVB1ny-UjN4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Basic Query Engine"
      ],
      "metadata": {
        "id": "K0l3oUS8NO-I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Compact (default)"
      ],
      "metadata": {
        "id": "TC2Vdq5LNe6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"compact\")\n",
        "\n",
        "response = query_engine.query(\"What do you use for nodejs?\")\n",
        "\n",
        "display_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 261
        },
        "id": "Lb9CsvvQNR9K",
        "outputId": "898debdb-63df-4809-f1c8-316a2b1e2189"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Based on the information provided in the context, the author uses a variety of tools and libraries for Node.js development, including:\n* Bun: The author prefers using Bun instead of Node.\n* Deno: The author finds Deno interesting too.\n* H3: The author finds the H3 library nice for HTTP requests.\n* Node.js: The author mentions using Node.js and mentions several resources related to Node.js, including Node.Dev, the original presentation by Ryan Dahl, and Node.js Best Practices.\n* Fastify: The author mentions Fastify as a fast and low-overhead web framework for Node.js.\n* Ndb: The author mentions improved debugging experience for Node.js enabled by Chrome DevTools.\n* Ncc: The author mentions a simple CLI for compiling a Node.js module into a single file.\n* TestCafe: The author mentions a tool for automating end-to-end web testing.\n* Redbird: The author mentions a modern reverse proxy for Node.js.\n* ndb: The author mentions improved debugging experience for Node.js enabled by Chrome DevTools.\n* Fastify-plugin: The author mentions a plugin"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Refine"
      ],
      "metadata": {
        "id": "p8WNEWO6NeEJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"refine\")\n",
        "\n",
        "response = query_engine.query(\"Do you use cloudflare to deploy web services?\")\n",
        "\n",
        "display_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 81
        },
        "id": "91CZsrtjNi4I",
        "outputId": "89f4f244-b663-4081-b8cc-adc3ff0eebc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Based on the new context provided, the author does not use Cloudflare for deploying web services. The author prefers Cloudflare Workers for APIs, Fly and Railway are also mentioned as options, and they also use Vercel and Netlify for serving websites. Additionally, they mention that they are looking into Cloudflare Pages as their API is already on Cloudflare Workers."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Tree Summarize"
      ],
      "metadata": {
        "id": "EBr8vyabNSmK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query_engine = vector_index.as_query_engine(response_mode=\"tree_summarize\")\n",
        "\n",
        "response = query_engine.query(\"What do you use for nodejs?\")\n",
        "\n",
        "display_response(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 278
        },
        "id": "X3YTKZXVNZ0R",
        "outputId": "1b24f7b2-e83e-440f-e6e1-ce65f1bfc596"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "**`Final Response:`** Based on the information provided in the context, the most commonly used tools and technologies for Node.js are:\n* Bun: A lightweight and fast HTTP library.\n* Deno: An interesting alternative to Node.js.\n* Tao of Node: A great talk on JavaScript promises.\n* Fastify: A fast and low-overhead web framework for Node.js.\n* Ndb: An improved debugging experience for Node.js enabled by Chrome DevTools.\n* ndb-cli: A simple CLI for compiling a Node.js module into a single file.\n* TestCafe: A Node.js tool for automating end-to-end web testing.\n* Node.js Best Practices: A guide for writing efficient and scalable server-side applications.\n* Stability first: A guide for writing stable Node.js applications.\n* David: A Node.js module that tells you when your package dependencies are out of date.\n* Httpie: A Node.js HTTP client as easy as pie.\n* Bull: A premium queue package for handling distributed jobs and messages in NodeJS.\n* Depcheck: A tool for checking your npm module for unused dependencies."
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## References\n",
        "\n",
        "- [Llama-index](https://colab.research.google.com/drive/14N-hmJ87wZsFqHktrw40OU6sVcsiSzlQ?usp=sharing) notebook"
      ],
      "metadata": {
        "id": "rlNTN2D0NCqd"
      }
    }
  ]
}